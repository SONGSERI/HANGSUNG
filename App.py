import streamlit as st
import pandas as pd
import numpy as np
from typing import List

from db import load_table


from analysis_quality import (
    run_quality_risk_analysis,
    QualityRiskParams,
)
from analysis_equipment import (
    run_equipment_anomaly_analysis,
    EquipmentAnomalyParams,
)
from analysis_production import (
    build_lot_machine_view,
    production_kpis,
)


def ensure_columns(df: pd.DataFrame, required_columns: list[str]) -> pd.DataFrame:

    if df.empty:
        return pd.DataFrame(columns=required_columns)

    result = df.copy()
    for col in required_columns:
        if col not in result.columns:
            result[col] = pd.Series(dtype="object")
    return result

# =========================
# Page Config
# =========================
st.set_page_config(
    page_title="SMT Analysis Lab",
    layout="wide",
)

st.title("SMT Analysis Lab")
st.caption("PostgreSQL ê¸°ë°˜ SMT ë¶„ì„ ì‹¤í—˜ ë„êµ¬")

# =========================
# DB Load
# =========================
@st.cache_data(show_spinner="DBì—ì„œ ë°ì´í„° ë¡œë”© ì¤‘...")
def load_data():
    def safe_load(table_name: str) -> pd.DataFrame:
        try:
            return load_table(table_name)
        except Exception:
            return pd.DataFrame()

    lot = safe_load("lot")
    lot_machine = safe_load("lot_machine")
    machine = safe_load("machine")
    time_summary = safe_load("machine_time_summary")
    pickup_summary = safe_load("pickup_error_summary")
    stop_log = safe_load("stop_log")
    stop_reason = safe_load("stop_reason")
    component = safe_load("component")
    component_pickup_summary = safe_load("component_pickup_summary")
    tag_info = safe_load("tag_info")
    tag_spec = safe_load("tag_spec")
    tag_realtime = safe_load("tag_realtime")

    return (
        lot,
        lot_machine,
        machine,
        time_summary,
        pickup_summary,
        stop_log,
        stop_reason,
        component,
        component_pickup_summary,
        tag_info,
        tag_spec,
        tag_realtime,
    )


(
    lot,
    lot_machine,
    machine,
    time_summary,
    pickup_summary,
    stop_log,
    stop_reason,
    component,
    component_pickup_summary,
    tag_info,
    tag_spec,
    tag_realtime,
) = load_data()

lot = ensure_columns(lot, ["lot_id", "lot_name", "start_time", "end_time", "lane"])
lot_machine = ensure_columns(lot_machine, ["lot_machine_id", "lot_id", "machine_id"])
machine = ensure_columns(machine, ["machine_id", "line_id", "stage_no", "machine_order"])
time_summary = ensure_columns(
    time_summary,
    [
        "lot_machine_id",
        "power_on_time_sec",
        "running_time_sec",
        "real_running_time_sec",
        "total_stop_time_sec",
        "transfer_time_sec",
        "board_recognition_time_sec",
        "placement_time_sec",
    ],
)
pickup_summary = ensure_columns(
    pickup_summary,
    [
        "lot_machine_id",
        "total_pickup_count",
        "total_error_count",
        "pickup_error_count",
        "recognition_error_count",
        "thick_error_count",
        "placement_error_count",
        "part_drop_error_count",
        "transfer_unit_part_drop_error_count",
        "pre_pickup_inspection_error_count",
    ],
)

# =========================
# Base View (ê³µí†µ Fact)
# =========================
lot_machine_view = build_lot_machine_view(
    lot,
    lot_machine,
    machine,
    time_summary,
    pickup_summary,
)

# =========================
# Sidebar Menu
# =========================
menu = st.sidebar.radio(
    "ë¶„ì„ ì„ íƒ",
    [
        "ğŸ“Š ìƒì‚° ë¶„ì„",
        "ğŸ›  ì„¤ë¹„ ì´ìƒ ë¶„ì„",
        "ğŸ§ª í’ˆì§ˆ ë¶„ì„",
        "ğŸ“ˆ ERD í•µì‹¬ ë¶„ì„",
    ],
)

with st.sidebar.expander("ê³µí†µ ì¡°ê±´", expanded=True):
    line_filter = st.multiselect(
        "ë¼ì¸",
        sorted(lot_machine_view["line_id"].dropna().unique().tolist()),
    )

# í•„í„° ì ìš©
if line_filter:
    lot_machine_view = lot_machine_view[
        lot_machine_view["line_id"].isin(line_filter)
    ]

# =========================
# ğŸ“Š ìƒì‚° ë¶„ì„
# =========================
if menu == "ğŸ“Š ìƒì‚° ë¶„ì„":
    st.header("ğŸ“Š ìƒì‚° ë¶„ì„")

    if st.button("Run ìƒì‚° ë¶„ì„"):
        result = production_kpis(lot_machine_view)

        st.subheader("LOT ê¸°ì¤€ KPI")
        st.dataframe(
            result["lot_level"].head(20),
            use_container_width=True,
        )

# =========================
# ğŸ›  ì„¤ë¹„ ì´ìƒ ë¶„ì„
# =========================
elif menu == "ğŸ›  ì„¤ë¹„ ì´ìƒ ë¶„ì„":
    st.header("ğŸ›  ì„¤ë¹„ ì´ìƒ ë¶„ì„")

    with st.expander("ì„¤ë¹„ ì´ìƒ íŒŒë¼ë¯¸í„°", expanded=True):
        w_stop_time = st.slider("ì •ì§€ì‹œê°„ ê°€ì¤‘ì¹˜", 0.5, 2.0, 1.0)
        w_stop_count = st.slider("ì •ì§€íšŸìˆ˜ ê°€ì¤‘ì¹˜", 0.0, 2.0, 0.5)
        w_error_ratio = st.slider("ERROR ë¹„ì¤‘ ê°€ì¤‘ì¹˜", 0.0, 3.0, 1.0)
        method = st.selectbox("ì´ìƒ íƒì§€ ë°©ë²•", ["zscore", "iqr"])

    if st.button("Run ì„¤ë¹„ ì´ìƒ ë¶„ì„"):
        params = EquipmentAnomalyParams(
            w_stop_time=w_stop_time,
            w_stop_count=w_stop_count,
            w_error_ratio=w_error_ratio,
            anomaly_method=method,
        )

        result = run_equipment_anomaly_analysis(
            lot_machine_view,
            stop_log,
            stop_reason,
            params,
        )

        st.subheader("ì´ìƒ ì„¤ë¹„ TOP")
        st.dataframe(result.head(20), use_container_width=True)

# =========================
# ğŸ§ª í’ˆì§ˆ ë¶„ì„
# =========================
elif menu == "ğŸ§ª í’ˆì§ˆ ë¶„ì„":
    st.header("ğŸ§ª í’ˆì§ˆ ë¶„ì„")

    with st.expander("í’ˆì§ˆ ë¦¬ìŠ¤í¬ íŒŒë¼ë¯¸í„°", expanded=True):
        w_pickup = st.slider("Pickup Error ê°€ì¤‘ì¹˜", 0.5, 3.0, 1.0)
        w_recognition = st.slider("Recognition Error ê°€ì¤‘ì¹˜", 0.5, 3.0, 1.0)
        w_pre_pickup = st.slider("Pre-Pickup Error ê°€ì¤‘ì¹˜", 0.0, 2.0, 0.5)
        w_stop = st.slider("Stop Time ê°€ì¤‘ì¹˜", 0.0, 2.0, 0.5)
        min_pickup = st.number_input("ìµœì†Œ Pickup ìˆ˜", 100, 10000, 1000)

    if st.button("Run í’ˆì§ˆ ë¶„ì„"):
        params = QualityRiskParams(
            w_pickup=w_pickup,
            w_recognition=w_recognition,
            w_pre_pickup=w_pre_pickup,
            w_stop_ratio=w_stop,
            min_pickup_count=min_pickup,
        )

        result = run_quality_risk_analysis(
            lot,
            lot_machine,
            machine,
            time_summary,
            pickup_summary,
            params,
        )

        st.subheader("LOT í’ˆì§ˆ Risk TOP")
        st.dataframe(
            result[
                ["lot_id", "machine_id", "risk_score", "risk_level"]
            ].head(20),
            use_container_width=True,
        )

# =========================
# ğŸ“ˆ ERD í•µì‹¬ ë¶„ì„
# =========================
elif menu == "ğŸ“ˆ ERD í•µì‹¬ ë¶„ì„":
    st.header("ğŸ“ˆ ERD í•µì‹¬ ë¶„ì„")
    analysis_tab = st.selectbox(
        "ë¶„ì„ í•­ëª©",
        [
            "Top ì •ì§€ì½”ë“œ 10ê°œ ì‹œê°„ì†ì‹¤ ê¸°ì—¬ë„",
            "ì„¤ë¹„ë³„ ê°€ë™ë¥  vs ì—ëŸ¬ìœ¨ ë§¤íŠ¸ë¦­ìŠ¤",
            "ë¶€í’ˆ(Part Number)ë³„ ì—ëŸ¬ Pareto",
            "íƒœê·¸ ìŠ¤í™ ì´íƒˆ ìƒìœ„ 20ê°œ",
        ],
    )

    if analysis_tab == "Top ì •ì§€ì½”ë“œ 10ê°œ ì‹œê°„ì†ì‹¤ ê¸°ì—¬ë„":
        required = {"stop_reason_code", "duration_sec", "stop_count", "lot_machine_id"}
        if stop_log.empty or not required.issubset(stop_log.columns):
            st.warning("`stop_log` í…Œì´ë¸”(í•„ìˆ˜ ì»¬ëŸ¼ í¬í•¨)ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            stop_df = stop_log.copy()
            stop_df["duration_sec"] = pd.to_numeric(stop_df["duration_sec"], errors="coerce").fillna(0)
            stop_df["stop_count"] = pd.to_numeric(stop_df["stop_count"], errors="coerce").fillna(0)

            by_reason = (
                stop_df.groupby("stop_reason_code", dropna=False)
                .agg(total_duration_sec=("duration_sec", "sum"), total_stop_count=("stop_count", "sum"))
                .reset_index()
                .sort_values("total_duration_sec", ascending=False)
            )

            total_duration = by_reason["total_duration_sec"].sum()
            by_reason["contribution_pct"] = np.where(
                total_duration > 0,
                by_reason["total_duration_sec"] / total_duration * 100,
                0.0,
            )

            if not stop_reason.empty and {"stop_reason_code", "stop_reason_name", "stop_reason_group"}.issubset(stop_reason.columns):
                by_reason = by_reason.merge(
                    stop_reason[["stop_reason_code", "stop_reason_name", "stop_reason_group"]],
                    on="stop_reason_code",
                    how="left",
                )

            top10 = by_reason.head(10)
            st.metric("ì „ì²´ ì •ì§€ì‹œê°„(ì´ˆ)", f"{int(total_duration):,}")
            st.dataframe(top10, use_container_width=True)
            st.bar_chart(
                top10.set_index("stop_reason_code")["total_duration_sec"],
                use_container_width=True,
            )

    elif analysis_tab == "ì„¤ë¹„ë³„ ê°€ë™ë¥  vs ì—ëŸ¬ìœ¨ ë§¤íŠ¸ë¦­ìŠ¤":
        required = {
            "machine_id",
            "power_on_time_sec",
            "running_time_sec",
            "total_pickup_count",
            "total_error_count",
        }
        if lot_machine_view.empty or not required.issubset(lot_machine_view.columns):
            st.warning("`lot_machine_view` ê³„ì‚°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ë¶€ì¡±í•´ ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            matrix_df = lot_machine_view.copy()
            matrix_df["power_on_time_sec"] = pd.to_numeric(matrix_df["power_on_time_sec"], errors="coerce")
            matrix_df["running_time_sec"] = pd.to_numeric(matrix_df["running_time_sec"], errors="coerce")
            matrix_df["total_pickup_count"] = pd.to_numeric(matrix_df["total_pickup_count"], errors="coerce").fillna(0)
            matrix_df["total_error_count"] = pd.to_numeric(matrix_df["total_error_count"], errors="coerce").fillna(0)

            by_machine = (
                matrix_df.groupby("machine_id", dropna=False)
                .agg(
                    power_on_time_sec=("power_on_time_sec", "sum"),
                    running_time_sec=("running_time_sec", "sum"),
                    total_pickup_count=("total_pickup_count", "sum"),
                    total_error_count=("total_error_count", "sum"),
                )
                .reset_index()
            )
            by_machine["uptime_ratio"] = by_machine["running_time_sec"] / by_machine["power_on_time_sec"].replace(0, np.nan)
            by_machine["error_rate"] = by_machine["total_error_count"] / by_machine["total_pickup_count"].replace(0, np.nan)

            x_median = by_machine["uptime_ratio"].median()
            y_median = by_machine["error_rate"].median()
            by_machine["quadrant"] = np.select(
                [
                    (by_machine["uptime_ratio"] >= x_median) & (by_machine["error_rate"] < y_median),
                    (by_machine["uptime_ratio"] >= x_median) & (by_machine["error_rate"] >= y_median),
                    (by_machine["uptime_ratio"] < x_median) & (by_machine["error_rate"] < y_median),
                ],
                ["ìš°ìˆ˜(ê³ ê°€ë™Â·ì €ì—ëŸ¬)", "í’ˆì§ˆ ê°œì„  í•„ìš”", "ê°€ë™ ê°œì„  í•„ìš”"],
                default="í•µì‹¬ ê°œì„  ëŒ€ìƒ",
            )

            st.caption(f"ì¤‘ì•™ê°’ ê¸°ì¤€ì„ : ê°€ë™ë¥ ={x_median:.3f}, ì—ëŸ¬ìœ¨={y_median:.3%}")
            st.dataframe(by_machine.sort_values(["error_rate", "uptime_ratio"], ascending=[False, True]), use_container_width=True)
            st.scatter_chart(
                by_machine,
                x="uptime_ratio",
                y="error_rate",
                size="total_pickup_count",
                color="quadrant",
                use_container_width=True,
            )

    elif analysis_tab == "ë¶€í’ˆ(Part Number)ë³„ ì—ëŸ¬ Pareto":
        required = {"component_id", "pickup_count", "error_count"}
        if component_pickup_summary.empty or not required.issubset(component_pickup_summary.columns):
            st.warning("`component_pickup_summary` í…Œì´ë¸”(í•„ìˆ˜ ì»¬ëŸ¼ í¬í•¨)ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            comp_df = component_pickup_summary.copy()
            comp_df["pickup_count"] = pd.to_numeric(comp_df["pickup_count"], errors="coerce").fillna(0)
            comp_df["error_count"] = pd.to_numeric(comp_df["error_count"], errors="coerce").fillna(0)

            by_part = comp_df.groupby("component_id", dropna=False).agg(
                pickup_count=("pickup_count", "sum"),
                error_count=("error_count", "sum"),
            ).reset_index()

            if not component.empty and {"component_id", "part_number"}.issubset(component.columns):
                by_part = by_part.merge(
                    component[["component_id", "part_number"]],
                    on="component_id",
                    how="left",
                )
            else:
                by_part["part_number"] = by_part["component_id"]

            by_part = by_part.groupby("part_number", dropna=False).agg(
                pickup_count=("pickup_count", "sum"),
                error_count=("error_count", "sum"),
            ).reset_index()
            by_part = by_part.sort_values("error_count", ascending=False)

            total_error = by_part["error_count"].sum()
            by_part["error_contribution_pct"] = np.where(
                total_error > 0,
                by_part["error_count"] / total_error * 100,
                0.0,
            )
            by_part["cumulative_pct"] = by_part["error_contribution_pct"].cumsum()
            by_part["error_rate"] = by_part["error_count"] / by_part["pickup_count"].replace(0, np.nan)

            top_n = st.slider("Pareto í‘œì‹œ ê°œìˆ˜", min_value=10, max_value=min(100, len(by_part) if len(by_part) > 0 else 10), value=min(20, len(by_part) if len(by_part) > 0 else 10))
            top_parts = by_part.head(top_n)

            st.dataframe(top_parts, use_container_width=True)
            st.bar_chart(top_parts.set_index("part_number")["error_count"], use_container_width=True)

    elif analysis_tab == "íƒœê·¸ ìŠ¤í™ ì´íƒˆ ìƒìœ„ 20ê°œ":
        required_rt = {"tag_id", "tag_value"}
        required_spec = {"tag_id", "spec_type", "spec_value"}

        if tag_realtime.empty or tag_spec.empty or not required_rt.issubset(tag_realtime.columns) or not required_spec.issubset(tag_spec.columns):
            st.warning("`tag_realtime` ë˜ëŠ” `tag_spec` í…Œì´ë¸”(í•„ìˆ˜ ì»¬ëŸ¼ í¬í•¨)ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¶„ì„ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            rt_df = tag_realtime.copy()
            sp_df = tag_spec.copy()
            rt_df["tag_value"] = pd.to_numeric(rt_df["tag_value"], errors="coerce")
            sp_df["spec_value"] = pd.to_numeric(sp_df["spec_value"], errors="coerce")

            spec_pivot = (
                sp_df[sp_df["spec_type"].isin(["LCL", "UCL"])][["tag_id", "spec_type", "spec_value"]]
                .pivot_table(index="tag_id", columns="spec_type", values="spec_value", aggfunc="last")
                .reset_index()
            )

            merged = rt_df.merge(spec_pivot, on="tag_id", how="inner")
            merged = merged[merged["tag_value"].notna()]
            merged["out_of_spec"] = (
                (merged["LCL"].notna() & (merged["tag_value"] < merged["LCL"]))
                | (merged["UCL"].notna() & (merged["tag_value"] > merged["UCL"]))
            )

            outlier = (
                merged.groupby("tag_id", dropna=False)
                .agg(total_count=("tag_id", "size"), out_of_spec_count=("out_of_spec", "sum"))
                .reset_index()
            )
            outlier["out_of_spec_rate"] = outlier["out_of_spec_count"] / outlier["total_count"].replace(0, np.nan)

            if not tag_info.empty and {"tag_id", "tag_name", "tag_category_id"}.issubset(tag_info.columns):
                outlier = outlier.merge(
                    tag_info[["tag_id", "tag_name", "tag_category_id"]],
                    on="tag_id",
                    how="left",
                )

            top20 = outlier.sort_values(["out_of_spec_count", "out_of_spec_rate"], ascending=False).head(20)
            st.dataframe(top20, use_container_width=True)
            st.bar_chart(top20.set_index("tag_id")["out_of_spec_count"], use_container_width=True)
